package llm

import (
	"context"
	"fmt"

	"github.com/openshift-pipelines/pipelines-as-code/pkg/apis/pipelinesascode/v1alpha1"
	"github.com/openshift-pipelines/pipelines-as-code/pkg/params"
	"github.com/openshift-pipelines/pipelines-as-code/pkg/params/info"
	"github.com/openshift-pipelines/pipelines-as-code/pkg/provider"
	tektonv1 "github.com/tektoncd/pipeline/pkg/apis/pipeline/v1"
	"go.uber.org/zap"
)

// OutputHandler handles the output of LLM analysis results to various destinations.
type OutputHandler struct {
	run    *params.Run
	logger *zap.SugaredLogger
}

// NewOutputHandler creates a new output handler.
func NewOutputHandler(run *params.Run, logger *zap.SugaredLogger) *OutputHandler {
	return &OutputHandler{
		run:    run,
		logger: logger,
	}
}

// HandleOutput processes the LLM analysis output according to the role configuration.
func (h *OutputHandler) HandleOutput(ctx context.Context, repo *v1alpha1.Repository, _ *tektonv1.PipelineRun, result AnalysisResult, event *info.Event, prov provider.Interface) error {
	if repo.Spec.Settings == nil || repo.Spec.Settings.AIAnalysis == nil {
		return fmt.Errorf("AI analysis configuration is nil")
	}

	// Find the role configuration
	var roleConfig *v1alpha1.AnalysisRole
	for _, role := range repo.Spec.Settings.AIAnalysis.Roles {
		if role.Name == result.Role {
			roleConfig = &role
			break
		}
	}

	if roleConfig == nil {
		return fmt.Errorf("role configuration not found for %s", result.Role)
	}

	output := roleConfig.GetOutput()
	if output != "pr-comment" {
		return fmt.Errorf("unsupported output destination: %s (only 'pr-comment' is currently supported)", output)
	}

	return h.postPRComment(ctx, result, event, prov)
}

// postPRComment posts LLM analysis as a PR comment.
func (h *OutputHandler) postPRComment(ctx context.Context, result AnalysisResult, event *info.Event, prov provider.Interface) error {
	if event.PullRequestNumber == 0 {
		h.logger.Debug("No pull request associated with this event, skipping PR comment")
		return nil
	}

	// Format the comment with LLM analysis
	comment := fmt.Sprintf("## ðŸ¤– AI Analysis - %s\n\n%s\n\n---\n*Generated by Pipelines-as-Code LLM Analysis*",
		result.Role, result.Response.Content)

	// Create a unique marker for this analysis role to allow updates
	updateMarker := fmt.Sprintf("llm-analysis-%s", result.Role)

	if err := prov.CreateComment(ctx, event, comment, updateMarker); err != nil {
		return fmt.Errorf("failed to create PR comment: %w", err)
	}

	h.logger.Infof("Posted LLM analysis as PR comment for role %s", result.Role)
	return nil
}
