apiVersion: tekton.dev/v1beta1
kind: StepAction
metadata:
  name: cache-upload
  annotations:
    tekton.dev/pipelines.minVersion: "0.56.0"
    tekton.dev/tags: "cache"
spec:
  params:
    - name: patterns
      description: |
        Regular expression to select files to include to compute the hash.
        For example, in the case of a Go project, you can use `go.mod` for this, so the value would be "**/go.sum" (to work with possible sub go modules as well).
      type: array
    - name: target
      description: |
        The target from where the cache should be uploaded. It's a URI with the scheme defining the "provider". In addition, one can add a {{hash}} variable to use the computed hash in the reference (oci image tags, path in s3, â€¦)
        Currently supported:
        - oci:// (e.g. oci://quay.io/vdemeester/go-cache:{{hash}}
        - s3:// (e.g. s3://
      type: string
    - name: cachePath
      description: |
        Path where to extract the cache content.
        It can refer any folder, backed by a workspace or a volume, or nothing.
      type: string
    - name: workingdir
      description: |
        The working dir from where the files patterns needs to be taken
      type: string
    - name: insecure
      description: |
        Whether to use insecure mode for fetching the cache
      type: string
      default: "false"
    - name: fetched
      description: |
        Wether cache was fetched or not previously
      type: string
      default: "false"
    - name: force-cache-upload
      description: |
        Whether to force the cache upload even if it was fetched previously
      type: string
      default: "false"
    - name: googleCredentialsPath
      description: |
        The path where to find the google credentials. If left empty, it is ignored.
      type: string
      default: ""
    - name: awsConfigFile
      description: |
        The path to the aws config file. If left empty, it is ignored.
      type: string
      default: ""
    - name: awsCredentialFile
      description: |
        The path to find the aws credentials file. If left empty, it is ignored.
      type: string
      default: ""
    - name: blobQueryParams
      description: |
        Blob Query Params to support configure s3, gcs and azure. This is optional unless some additional features of storage providers are required like s3 acceleration, fips, pathstyle,etc
      type: string
      default: ""
  env:
    - name: PARAM_TARGET
      value: $(params.target)
    - name: PARAM_CACHE_PATH
      value: $(params.cachePath)
    - name: PARAM_WORKINGDIR
      value: $(params.workingdir)
    - name: PARAM_INSECURE
      value: $(params.insecure)
    - name: RESULT_CACHE_FETCHED
      value: $(params.fetched)
    - name: PARAM_FORCE_CACHE_UPLOAD
      value: $(params.force-cache-upload)
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: $(params.googleCredentialsPath)
    - name: AWS_CONFIG_FILE
      value: $(params.awsConfigFile)
    - name: AWS_SHARED_CREDENTIALS_FILE
      value: $(params.awsCredentialFile)
    - name: BLOB_QUERY_PARAMS
      value: $(params.blobQueryParams)
  image: ghcr.io/chmouel/tekton-caches/cache@sha256:7b543966be2c4ef9bc439c0a6d262dd0f284216c7c292ba35c15b9ef5bca84c6
  args: ["$(params.patterns[*])"]
  script: |
    #!/usr/bin/env sh
    set -x
    if [[ ${PARAM_FORCE_CACHE_UPLOAD} == "false" && ${RESULT_CACHE_FETCHED} == "true" ]]; then
      echo "no need to upload cache"
      exit 0
    fi

    PATTERN_FLAGS=""
    echo "Patterns: $*"
    for p in $*; do
      PATTERN_FLAGS="${PATTERN_FLAGS} --pattern ${p}"
    done

    # Try three times
    for i in {1..3};do
      /ko-app/cache upload ${PATTERN_FLAGS} \
                          --target ${PARAM_TARGET} \
                          --folder ${PARAM_CACHE_PATH} \
                          --insecure ${PARAM_INSECURE} \
                          --workingdir ${PARAM_WORKINGDIR}
      ret=$?
      if [[ ${ret} == 0 ]];then
        exit 0
      fi
    done
    exit 1
